<!--
SPDX-FileCopyrightText: 2025 robot-visual-perception

SPDX-License-Identifier: CC-BY-4.0
-->

# OptiBot

Minimal real-time object and distance detection via YOLO on a WebRTC video stream.

## What’s included
- FastAPI + aiortc backend streaming webcam frames
- YOLOv8n inference (Ultralytics) on the server
- Rough monocular distance estimate per detection
- WebRTC DataChannel sending metadata to the client
- React + Vite frontend showing the remote stream and detection stats

## Run backend (WebRTC)
Prereqs: Python 3.11

1) Install dependencies
```
make dev
```

2) Start the webcam service
```
make run-webcam-local
```
3) Start the analyzer service (separate terminal)
```
make run-analyzer-local
```
The first analyzer start will download `yolov8n.pt` automatically (this will take some time)

Optional environment variables (more relevant later):
- `CAMERA_INDEX` (default 0) – select webcam device
- `REGION_SIZE` (default 5) – size of the central bounding box region where we take the mean of the depth map from (should be odd for symmetry)
- `SCALE_FACTOR` (default 432.0) – scaling of the relative depth map generated by MiDaS (must be determined empirically)

> Check `src/backend/common/config.py`.

## Run frontend
Prereqs: Node 20.

1) Install deps
```
make dev
```
> `make dev` installs both frontend and backend.

2) Start dev server
```
make run-frontend-local
```
Open the shown URL in your console.

## Notes
- The webcam service mirrors and streams raw frames only; the analyzer handles YOLO inference and overlays.
- Analyzer inference is throttled to ~10 Hz to keep latency low.

> IMPORTANT: Please read the `CONTRIBUTING.md`.
